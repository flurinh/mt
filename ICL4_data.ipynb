{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "juvenile-hunger",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "english-sharp",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (gpcrdb_soup.py, line 143)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m\"C:\\Users\\Sideadmin\\.conda\\envs\\mt\\lib\\site-packages\\IPython\\core\\interactiveshell.py\"\u001b[0m, line \u001b[0;32m3427\u001b[0m, in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[0;32m\"<ipython-input-1-06c13ef130a8>\"\u001b[0m, line \u001b[0;32m2\u001b[0m, in \u001b[0;35m<module>\u001b[0m\n    from utils2 import *\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Sideadmin\\PycharmProjects\\mt\\utils2.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[1;36m, in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    from gpcrdb_soup import *\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\Sideadmin\\PycharmProjects\\mt\\gpcrdb_soup.py\"\u001b[1;36m, line \u001b[1;32m143\u001b[0m\n\u001b[1;33m    fname = folder + '/' + url[-loc+4:-loc] + '.' + fileformat\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "from utils2 import *\n",
    "from utils3 import *\n",
    "from gpcrdb_soup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-chain",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import Bio\n",
    "import yaml\n",
    "import os\n",
    "from functools import partial\n",
    "from operator import is_not\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp3(df: pd.DataFrame):\n",
    "    with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
    "        display(df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-latest",
   "metadata": {},
   "source": [
    "# GPCRDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "understood-patio",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_table' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-5b5dd4712506>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'get_table' is not defined"
     ]
    }
   ],
   "source": [
    "table = get_table(reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-murder",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "digital-therapist",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# t\n",
    "# Todo: https://www.ebi.ac.uk/training/online/sites/ebi.ac.uk.training.online/files/UniProt_programmatically_py3.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solved-identification",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = table\n",
    "\n",
    "# This is the thing we might want to specify with argparse\n",
    "filtered = df[df['Cl.'].str.contains('A')]\n",
    "filtered = filtered[filtered['Species'].str.contains('Human')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "processed-change",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "planned-classroom",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 2.1) find active state (complex i.p.)\n",
    "filtered_complex = filtered[filtered['Family'].str.contains('Gs')]\n",
    "active = filtered_complex[filtered_complex['State'].str.contains('Active')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "liquid-above",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# disp3(active)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "amateur-harrison",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor url in tqdm(active['pdb_link']):\\n    download_pdb(url, 'active')\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo: check if file already exists and use overwrite=True/False\n",
    "\"\"\"\n",
    "for url in tqdm(active['pdb_link']):\n",
    "    download_pdb(url, 'active')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-investigation",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "approved-kruger",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADRB2', 'GPR52', 'GPBAR', 'AA2AR', 'PE2R4']\n"
     ]
    }
   ],
   "source": [
    "# find inactive counter parts of the active proteins ==> use gene/uniprot, Family and species to match them\n",
    "\n",
    "genes = list(set(active['uniprot(gene)'].values.tolist()))\n",
    "print(genes)\n",
    "\n",
    "inactive = filtered[(filtered['uniprot(gene)'].isin(genes))\n",
    "                    & (filtered['State'].str.contains('Inactive')) \n",
    "                    & (filtered['Species'].str.contains('Human'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "resident-nevada",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"for url in tqdm(inactive['pdb_link']):\\n    download_pdb(url, 'inactive')\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"for url in tqdm(inactive['pdb_link']):\n",
    "    download_pdb(url, 'inactive')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "floating-pencil",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# disp3(inactive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "challenging-basket",
   "metadata": {},
   "source": [
    "## GPCRDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fossil-surfing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution: manual download for the entire A class\n",
    "al = load_alignment_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "surgical-mouse",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaning alignment\n"
     ]
    }
   ],
   "source": [
    "al_df, positions = clean_alignment(al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "induced-bracket",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>clean_id</th>\n",
       "      <th>TM7_combined</th>\n",
       "      <th>TM7_clean</th>\n",
       "      <th>H8_combined</th>\n",
       "      <th>H8_clean</th>\n",
       "      <th>roi_pos</th>\n",
       "      <th>roi_seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Human] 5-HT1A receptor</td>\n",
       "      <td>5-HT1A receptor</td>\n",
       "      <td>_______PTLLGAIINWLGYSNSLLNPVIYAYF___</td>\n",
       "      <td>PTLLGAIINWLGYSNSLLNPVIYAYF</td>\n",
       "      <td>___NKDFQNAFKKII______________</td>\n",
       "      <td>NKDFQNAFKKII</td>\n",
       "      <td>[7.31x30, 7.32x31, 7.33x32, 7.34x33, 7.35x34, ...</td>\n",
       "      <td>PTLLGAIINWLGYSNSLLNPVIYAYFNKDFQNAFKKII</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Human] 4iaq</td>\n",
       "      <td>4iaq</td>\n",
       "      <td>_______HLAIFDFFTWLGYLNSLINPIIYTMS___</td>\n",
       "      <td>HLAIFDFFTWLGYLNSLINPIIYTMS</td>\n",
       "      <td>___NEDFKQAFHKLI______________</td>\n",
       "      <td>NEDFKQAFHKLI</td>\n",
       "      <td>[7.31x30, 7.32x31, 7.33x32, 7.34x33, 7.35x34, ...</td>\n",
       "      <td>HLAIFDFFTWLGYLNSLINPIIYTMSNEDFKQAFHKLI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Human] 4iar</td>\n",
       "      <td>4iar</td>\n",
       "      <td>_______HLAIFDFFTWLGYLNSLINPIIYTM____</td>\n",
       "      <td>HLAIFDFFTWLGYLNSLINPIIYTM</td>\n",
       "      <td>___NEDFKQAFHKLI______________</td>\n",
       "      <td>NEDFKQAFHKLI</td>\n",
       "      <td>[7.31x30, 7.32x31, 7.33x32, 7.34x33, 7.35x34, ...</td>\n",
       "      <td>HLAIFDFFTWLGYLNSLINPIIYTMNEDFKQAFHKLI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID         clean_id  \\\n",
       "1  [Human] 5-HT1A receptor  5-HT1A receptor   \n",
       "2             [Human] 4iaq             4iaq   \n",
       "3             [Human] 4iar             4iar   \n",
       "\n",
       "                           TM7_combined                   TM7_clean  \\\n",
       "1  _______PTLLGAIINWLGYSNSLLNPVIYAYF___  PTLLGAIINWLGYSNSLLNPVIYAYF   \n",
       "2  _______HLAIFDFFTWLGYLNSLINPIIYTMS___  HLAIFDFFTWLGYLNSLINPIIYTMS   \n",
       "3  _______HLAIFDFFTWLGYLNSLINPIIYTM____   HLAIFDFFTWLGYLNSLINPIIYTM   \n",
       "\n",
       "                     H8_combined      H8_clean  \\\n",
       "1  ___NKDFQNAFKKII______________  NKDFQNAFKKII   \n",
       "2  ___NEDFKQAFHKLI______________  NEDFKQAFHKLI   \n",
       "3  ___NEDFKQAFHKLI______________  NEDFKQAFHKLI   \n",
       "\n",
       "                                             roi_pos  \\\n",
       "1  [7.31x30, 7.32x31, 7.33x32, 7.34x33, 7.35x34, ...   \n",
       "2  [7.31x30, 7.32x31, 7.33x32, 7.34x33, 7.35x34, ...   \n",
       "3  [7.31x30, 7.32x31, 7.33x32, 7.34x33, 7.35x34, ...   \n",
       "\n",
       "                                  roi_seq  \n",
       "1  PTLLGAIINWLGYSNSLLNPVIYAYFNKDFQNAFKKII  \n",
       "2  HLAIFDFFTWLGYLNSLINPIIYTMSNEDFKQAFHKLI  \n",
       "3   HLAIFDFFTWLGYLNSLINPIIYTMNEDFKQAFHKLI  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp3(al_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rotary-sociology",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-vatican",
   "metadata": {},
   "source": [
    "## PDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "considerable-hawaii",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13 proteins: ['7BZ2', '7D7M', '7CFM', '7DHI', '7CFN', '7DHR', '5G53', '6E67', '7BW0', '6LI3', '3SN6', '6NI3', '6GDG'].\n"
     ]
    }
   ],
   "source": [
    "files_a, prots_a = get_pdb_files(path='data/pdb/active/')  # Get all downloaded pdb files in specified path\n",
    "print(\"Found {} proteins: {}.\".format(len(prots_a), prots_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interior-durham",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 proteins: ['5OLV', '6PS7', '3REY', '5NLX', '6LPL', '5OLZ', '5YWY', '5IU7', '5JTB', '4EIY', '5D5A', '6PS3', '3UZA', '3PWH', '6PS5', '5MZJ', '3EML', '5K2B', '5NM4', '5D5B', '3UZC', '5NM2', '5IUB', '3D4S', '5VRA', '5IU4', '5OLO', '6PS6', '2R4R', '5D6L', '6WQA', '5OM1', '6PS2', '3NY8', '6S0Q', '5YHL', '6ZDR', '5N2R', '6LPJ', '3KJ6', '3VG9', '5OLG', '6AQF', '6MH8', '6ZDV', '5K2C', '6PS0', '3NY9', '6PS4', '4GBR', '2RH1', '2R4S', '5IUA', '5X7D', '5K2A', '5JQH', '3RFM', '5K2D', '6PRZ', '5OLH', '5UVI', '3VGA', '6S0L', '6JZH', '5UIG', '6OBA', '6LPK', '5IU8', '5MZP', '5OM4', '3PDS', '3NYA', '6PS1', '6GT3'].\n"
     ]
    }
   ],
   "source": [
    "# Data loading\n",
    "files_i, prots_i = get_pdb_files(path='data/pdb/inactive/')  # Get all downloaded pdb files in specified path\n",
    "print(\"Found {} proteins: {}.\".format(len(prots_i), prots_i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-coordinate",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "gross-group",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for alignment: https://gpcrdb.org/services/alignment/protein/7BZ2,7D7M,7CFM,7DHI,7CFN,7DHR,5G53,6E67,7BW0,6LI3,3SN6,6NI3,6GDG/TM7/\n",
      "Doesnt work anymore...\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    seg_aligns = get_alignment(prots_a)\n",
    "    print(yaml.dump(seg_aligns, default_flow_style=False))\n",
    "except:\n",
    "    print(\"Doesnt work anymore...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adopted-tsunami",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# since the identifiers are only human readable..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "coupled-memory",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "genes = list(al_df['clean_id'])\n",
    "\n",
    "l4=[]\n",
    "l5=[]\n",
    "l6=[]\n",
    "\n",
    "for g in genes:\n",
    "    if len(g) == 4:\n",
    "        l4.append(g)\n",
    "    elif len(g) == 5:\n",
    "        l5.append(g)\n",
    "    elif len(g) == 6:\n",
    "        l6.append(g)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "loose-provision",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4iaq', '4iar', '5v54', '6g79', '7c61', '6a93', '6a94', '6wgt', '6wh4', '6wha', '4ib4', '4nc3', '5tud', '5tvn', '6drx', '6dry', '6drz', '6ds0', '6bqg', '6bqh', '5cxv', '6oij', '6wjc', '3uon', '4mqs', '4mqt', '5yc8', '5zk3', '5zk8', '5zkb', '5zkc', '6oik', '6u1n', '5dsg', '6kp6', '6ol9', '6kux', '6kuy', '6k41', '6k42', '6kuw', '2r4r', '2r4s', '2rh1', '3d4s', '3kj6', '3ny8', '3ny9', '3nya', '3p0g', '3pds', '3sn6', '4gbr', '4lde', '4ldl', '4ldo', '4qkx', '5d5a', '5d5b', '5d6l', '5jqh', '5x7d', '6e67', '6mxt', '6n48', '6ni3', '6oba', '6prz', '6ps0', '6ps1', '6ps2', '6ps3', '6ps4', '6ps5', '6ps6', '7bz2', '7dhi', '7dhr', '6cm4', '6luq', '6vms', '7dfp', '3pbl', '5wiu', '5wiv', '3rze', '4yay', '4zud', '6do1', '6os0', '6os1', '6os2', '5unf', '5ung', '5unh', '5xjm', '6jod', '7c6a', '5vbl', '6knm', '5o9h', '6c1q', '6c1r', '5glh', '5gli', '5x93', '5xpr', '6igk', '6igl', '6k1q', '6lry', 'FPR1', '6lw5', '6omm', 'FPR3', '6ko5', '7br3', '6w25', '5zbh', '5zbq', '7ddz', '6os9', '6osa', '6pwc', '6up7', '4n6h', '4rwa', '4rwd', '6pt2', '6pt3', '4djh', '6b73', '6vi4', '4ea3', '5dhg', '5dhh', '4zj8', '4zjc', '6to7', '6tod', '6tos', '6tot', '6tp3', '6tp4', '6tp6', '6tq4', '6tq6', '6tq7', '6tq9', '6v9s', '4s0v', '5wqc', '5ws3', '6tpg', '6tpj', '6tpn', '3vw7', 'PAR1', '5ndd', '5ndz', '5nj6', 'PAR2', 'PAR3', 'PAR4', '6e59', '6hll', '6hlo', '6hlp', '6j20', '6j21', '6tpk', 'CCR1', '5T1A', '6gps', '6gpx', 'CCR2', 'CCR3', 'CCR4', '4mbs', '5uiw', '6akx', '6aky', '6meo', '6met', 'CCR5', '6wwz', 'CCR6', '6qzh', 'CCR7', 'CCR8', '5lwe', 'CCR9', '6lfl', '6lfm', '6lfo', '3odu', '3oe0', '3oe6', '3oe8', '3oe9', '4rws', 'XCR1', 'PKR1', 'PKR2', '4phu', '5kw2', '5tzr', '5tzy', '6rz4', '6rz5', '6rz6', '6rz7', '6rz8', '6rz9', '4z34', '4z35', '4z36', '3v2w', '3v2y', '5tgz', '5u09', '5xr8', '5xra', '6kpg', '6kqi', '6n4b', '5zty', '6kpc', '6kpf', '6pt0', '5zkp', '5zkq', '6d26', '6d27', '6ak3', '6m9t', '5yhl', '5ywy', '7d7m', '6iiu', '6iiv', '6me2', '6me3', '6me4', '6me5', '6ps8', '6me6', '6me7', '6me8', '6me9', '5n2s', '5uen', '6d9h', '2ydo', '2ydv', '3eml', '3pwh', '3qak', '3rey', '3rfm', '3uza', '3uzc', '3vg9', '3vga', '4eiy', '4ug2', '4uhr', '5g53', '5iu4', '5iu7', '5iu8', '5iua', '5iub', '5jtb', '5k2a', '5k2b', '5k2c', '5K2D', '5mzj', '5mzp', '5n2r', '5nlx', '5nm2', '5nm4', '5olg', '5olh', '5olo', '5olv', '5olz', '5om1', '5om4', '5uig', '5uvi', '5vra', '5wf5', '5wf6', '6aqf', '6gdg', '6gt3', '6jzh', '6lpj', '6lpk', '6lpl', '6mh8', '6ps7', '6s0l', '6s0q', '6wqa', '6zdr', '6zdv', '4xnv', '4xnw', '4ntj', '4pxz', '4py0', '7bw0', '7cfm', '7cfn', 'GPER', '4zwj', '5dgy', '5w0p', '6cmo', 'GPR1', 'GPR3', 'GPR4', 'GPR6', '6li0', '6li1', '6li2', '6li3', 'LGR4', 'LGR5', 'LGR6', 'MAS1']\n"
     ]
    }
   ],
   "source": [
    "print(l4)  # these are (all?) pdbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exotic-columbia",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(l5)  # these are?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "collaborative-grace",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# print(l6)  # another id.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "modular-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did i load active inactive again?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "engaging-creator",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-29d6b45c2935>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  inactive['pdb_lower'] = inactive.PDB.apply(lambda x: x.lower())\n"
     ]
    }
   ],
   "source": [
    "# This should be put into a function somewhere or just left out!\n",
    "inactive['pdb_lower'] = inactive.PDB.apply(lambda x: x.lower())\n",
    "active['pdb_lower'] = active.PDB.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "amber-bench",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "found = []\n",
    "for g in l4:\n",
    "    select = inactive[inactive['pdb_lower'].str.contains(g.lower())]\n",
    "    if len(select) > 0:\n",
    "        found.append(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "horizontal-miller",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 74 / 74 inactive proteins.\n"
     ]
    }
   ],
   "source": [
    "print(\"Found {} / {} inactive proteins.\".format(len(found), len(inactive)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "viral-hormone",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# check\n",
    "# print(sorted(list(inactive['PDB'].str.lower()))[:10])\n",
    "# print(sorted(l4)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historic-input",
   "metadata": {},
   "source": [
    "# Structures (PDB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-childhood",
   "metadata": {},
   "source": [
    "## Combine gpcrdb-table, pdb-structures and alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "appreciated-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIX: DO NOT USE ONLY CHAIN ID 0 ---> USE ALL CHAINS AND USE SEQ ALIGNMENT TO GET THE CORRECT CHAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "adult-plaza",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 13/13 [00:02<00:00,  4.42it/s]\n"
     ]
    }
   ],
   "source": [
    "structures_a = pdb_data(files_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abandoned-advancement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prot_id</th>\n",
       "      <th>prot_len</th>\n",
       "      <th>prot_seq</th>\n",
       "      <th>pp_ids</th>\n",
       "      <th>pp_lens</th>\n",
       "      <th>pp_seqs</th>\n",
       "      <th>psi_phi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3SN6</td>\n",
       "      <td>349</td>\n",
       "      <td>[T, E, D, Q, R, N, E, E, K, A, Q, R, E, A, N, ...</td>\n",
       "      <td>[0, 1, 2, 3]</td>\n",
       "      <td>[51, 115, 51, 132]</td>\n",
       "      <td>[TEDQRNEEKAQREANKKIEKQLQKDKQVYRATHRLLLLGAGESGK...</td>\n",
       "      <td>[[[None, -2.4757948598365656], [0.838827129769...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5G53</td>\n",
       "      <td>286</td>\n",
       "      <td>[S, S, V, Y, I, T, V, E, L, A, I, A, V, L, A, ...</td>\n",
       "      <td>[0, 1, 2]</td>\n",
       "      <td>[141, 53, 89]</td>\n",
       "      <td>[SSVYITVELAIAVLAILGNVLVCWAVWLNSNLQNVTNYFVVSLAA...</td>\n",
       "      <td>[[[None, 2.349491635258823], [-1.0346566470181...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6E67</td>\n",
       "      <td>458</td>\n",
       "      <td>[D, E, V, W, V, V, G, M, G, I, V, M, S, L, I, ...</td>\n",
       "      <td>[0]</td>\n",
       "      <td>[457]</td>\n",
       "      <td>[DEVWVVGMGIVMSLIVLAIVFGNVLVITAIAKFERLQTVTNYFIT...</td>\n",
       "      <td>[[[None, 2.4471797633510577], [-1.186672557221...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prot_id  prot_len                                           prot_seq  \\\n",
       "0    3SN6       349  [T, E, D, Q, R, N, E, E, K, A, Q, R, E, A, N, ...   \n",
       "1    5G53       286  [S, S, V, Y, I, T, V, E, L, A, I, A, V, L, A, ...   \n",
       "2    6E67       458  [D, E, V, W, V, V, G, M, G, I, V, M, S, L, I, ...   \n",
       "\n",
       "         pp_ids             pp_lens  \\\n",
       "0  [0, 1, 2, 3]  [51, 115, 51, 132]   \n",
       "1     [0, 1, 2]       [141, 53, 89]   \n",
       "2           [0]               [457]   \n",
       "\n",
       "                                             pp_seqs  \\\n",
       "0  [TEDQRNEEKAQREANKKIEKQLQKDKQVYRATHRLLLLGAGESGK...   \n",
       "1  [SSVYITVELAIAVLAILGNVLVCWAVWLNSNLQNVTNYFVVSLAA...   \n",
       "2  [DEVWVVGMGIVMSLIVLAIVFGNVLVITAIAKFERLQTVTNYFIT...   \n",
       "\n",
       "                                             psi_phi  \n",
       "0  [[[None, -2.4757948598365656], [0.838827129769...  \n",
       "1  [[[None, 2.349491635258823], [-1.0346566470181...  \n",
       "2  [[[None, 2.4471797633510577], [-1.186672557221...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp3(structures_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "duplicate-buying",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_a = structure_to_full(active, structures_a, al_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "agreed-traffic",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "full_a.to_pickle('full_a.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lined-memory",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 74/74 [00:14<00:00,  5.28it/s]\n"
     ]
    }
   ],
   "source": [
    "structures_i = pdb_data(files_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dying-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_i = structure_to_full(inactive, structures_i, al_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "raising-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_i.to_pickle('full_i.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-matthew",
   "metadata": {},
   "source": [
    "## Load Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "million-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_a = pd.read_pickle('full_a.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cognitive-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_a = full_a[full_a['uniprotid']!='RESIDUES'].dropna(subset=['uniprotid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "charitable-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "educational-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_i = pd.read_pickle('full_i.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "vietnamese-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_i = full_i[full_i['uniprotid']!='RESIDUES']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "challenging-craft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cloudy-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include Uniprot data\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "\n",
    "def get_uniprot(query='',query_type='PDB_ID'):\n",
    "    #query_type must be: \"PDB_ID\" or \"ACC\"\n",
    "    url = 'https://www.uniprot.org/' #This is the webser to retrieve the Uniprot data\n",
    "    params = {\n",
    "    'from':query_type,\n",
    "    'to':'ACC',\n",
    "    'format':'txt',\n",
    "    'query':query\n",
    "    }\n",
    "\n",
    "    data = urllib.parse.urlencode(params)\n",
    "    data = data.encode('ascii')\n",
    "    request = urllib.request.Request(url, data)\n",
    "    with urllib.request.urlopen(request) as response:\n",
    "        res = response.read()\n",
    "        page=BeautifulSoup(res).get_text()\n",
    "        page=page.splitlines()\n",
    "    return page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "exempt-garage",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = get_uniprot('6li3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "together-learning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q9Y2T5'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdbtouniprot('6li3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "antique-spanking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "searching = False\n",
    "regex = '^[a-zA-Z].{2}[ ].{3}'\n",
    "for _ in eg:\n",
    "    if 'SQ   ' in _:\n",
    "        searching = True\n",
    "        print(_)\n",
    "    elif searching == True:\n",
    "        if re.search(regex, _) and (not 'SQ   ' in _):\n",
    "            searching = False\n",
    "        else:\n",
    "            print(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "honest-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uniprot_topology(df):\n",
    "    def get_topo(x):\n",
    "        domains=[]\n",
    "        positions=[]\n",
    "        data=get_uniprot(query=x, query_type='ACC')\n",
    "        add_next_note = False\n",
    "        for line in data:\n",
    "            if 'FT   ' in line:\n",
    "                line=line.strip().replace('FT   ','')\n",
    "                if ('TOPO_DOM' in line) or ('TRANSMEM        ' in line):\n",
    "                    add_next_note=True\n",
    "                    line = line.replace('TOPO_DOM        ', '').replace('TRANSMEM        ', '')\n",
    "                    positions.append((line.split('.')[0], line.split('.')[2]))\n",
    "                if ('note' in line) and add_next_note is True:\n",
    "                    line = line.replace('                /note=', '').replace('\\\"','')\n",
    "                    domains.append(line.replace('                /note=', '').replace('\\\"',''))\n",
    "                    add_next_note=False\n",
    "        return [domains, positions]\n",
    "    lambdafunc = lambda x: pd.Series([get_topo(x.uniprotid)[0],\n",
    "                                      get_topo(x.uniprotid)[1]])\n",
    "    df[['Topology', 'topo_pos']] = df.apply(lambdafunc, axis=1).copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bottom-garbage",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_a = add_uniprot_topology(full_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "negative-intention",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_i = add_uniprot_topology(full_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "unauthorized-grammar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    []\n",
       "5    []\n",
       "6    []\n",
       "7    []\n",
       "8    []\n",
       "Name: Topology, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_i['Topology'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sized-leader",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    []\n",
       "5    []\n",
       "6    []\n",
       "7    []\n",
       "8    []\n",
       "Name: topo_pos, dtype: object"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_i['topo_pos'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "underlying-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include Sifts data (which regions are included)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "moving-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils3 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "social-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maps_(full):\n",
    "    l = []\n",
    "    for i in range(len(full)):\n",
    "        uniprot_mappings = list_uniprot_pdb_mappings(full['pdb_lower'].iloc[i])[full['uniprotid'].iloc[i]]['mappings'][0]\n",
    "        l.append(uniprot_mappings)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "selected-knife",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maps(pdbs, mappings):\n",
    "    cols = ['pdb_lower', 'start_pdb', 'end_pdb', 'start_uniprot', 'end_uniprot']\n",
    "    maps = {}\n",
    "    for _ in range(len(mappings)):\n",
    "        start = l[_]['start']['residue_number']\n",
    "        end = l[_]['end']['residue_number']\n",
    "        unp_start = l[_]['unp_start']\n",
    "        unp_end = l[_]['unp_end']\n",
    "        data = [pdbs[_], start, end, unp_start, unp_end]\n",
    "        maps.update({_: data})\n",
    "    return pd.DataFrame.from_dict(data=maps).T.rename(columns = {k:cols[k] for k in range(len(cols))})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "maritime-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_a = get_maps_(full_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "statewide-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "# l_i = get_maps_(full_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "defensive-incentive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_i = get_maps(full_i['pdb_lower'].tolist(), l_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "first-transparency",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_i_ = pd.merge(full_i, mapping_i, on='pdb_lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "tropical-disney",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_a['pdb_lower']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "classical-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping_a = get_maps(full_a['pdb_lower'].tolist(), l_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adverse-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_a_ = pd.merge(full_a, mapping_a, on='pdb_lower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "vietnamese-chance",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# disp3(full_i_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collected-retreat",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "genetic-station",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if these numbers mean anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dried-stack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 get uniprot protein sequence ==> done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "modern-terrace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 compare full sequences  ==> wtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "supreme-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 compare sections that supposedly are \"mapped\"  ==> idk what is going on (well at least 1 of the 4 seqs i found on uniprot \n",
    "# corresponds to my true sequence (kinda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "planned-accessory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should let us evaluate where we have missing protein sections ==> bett"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "played-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 for each residue get the position (dont need anymore since we have )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "regional-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 for each residue get the angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "coupled-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 select target region based on position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-jacob",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "military-question",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-closing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "mediterranean-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 full position array  (tbd?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "parallel-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8 pad the selected angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "stuffed-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 make a sparse plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-bride",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-administrator",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-riding",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-shoulder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "prescription-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo: select only the mappings corresponding to the uniprot-id we already have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-constitutional",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integrated-meter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "chicken-stable",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_seg_to_seq(z, padding=None, padding_l=None, padding_r=0):\n",
    "    X = z[0]\n",
    "    Y = z[1]\n",
    "    pdb = z[2]\n",
    "    if (len(X) == 0) or (len(Y) == 0):\n",
    "        return None, None, None, None, None, None, None\n",
    "    a_ = pairwise2.align.globalms(X, Y, 3, -.5, -.1, -0.1)[0]\n",
    "    score = a_.score\n",
    "    score /= len(Y)  # Is this a balanced representation?\n",
    "    matching = [0 if (a_.seqB[i] == '-') else 1 for i in range(len(a_.seqB))]\n",
    "    # get mean\n",
    "    res_id = [idx for idx, val in enumerate(matching) if val != 0]\n",
    "    res_arr = np.asarray(res_id)\n",
    "    mean = np.mean(res_arr)\n",
    "    # get std\n",
    "    std = np.std(res_arr)\n",
    "    # get start\n",
    "    start = matching.index(1)\n",
    "    # get end\n",
    "    end = len(matching) - matching[::-1].index(1)\n",
    "    if padding != None:\n",
    "        start = max(0, start-padding)\n",
    "        end = min(len(X), end+padding)\n",
    "    if padding_l != None:\n",
    "        start = max(0, start-padding_l)\n",
    "    if padding_r != None:\n",
    "        end = min(len(X), end+padding_r)\n",
    "    return start, end, mean, std, score, res_id, pdb\n",
    "\n",
    "\n",
    "def get_align_dict(full: pd.DataFrame, section_name='TM7'):\n",
    "    l_seq = list(full['full_prot_seq'])\n",
    "    l_seg = list(full[section_name+'_clean'])\n",
    "    pdb = list(full['PDB'])\n",
    "    cols = ['start', 'end', 'mean', 'std', 'score', 'res', 'PDB']\n",
    "    cols = [section_name+'_'+x  if x != 'PDB' else 'PDB' for x in cols]\n",
    "    l = []\n",
    "    for z in zip(l_seq, l_seg, pdb):\n",
    "        values = align_seg_to_seq(z)\n",
    "        zipped = zip(cols, values)\n",
    "        a_s = dict(zipped)\n",
    "        l.append(a_s)\n",
    "    a_df = pd.DataFrame(columns=cols)\n",
    "    a_df = a_df.append(l, True)\n",
    "    return full.merge(a_df, how='inner', left_on='PDB', right_on='PDB')  # ignore_index=True\n",
    "\n",
    "\n",
    "def df_align_func(df, section_name, max_std=100, min_score=0.0):\n",
    "    def align(x, max_std, min_score):\n",
    "        seg = x[1]\n",
    "        pps = x[0]\n",
    "        min_std = 100\n",
    "        start_best = 0\n",
    "        end_best = 0\n",
    "        # print(\"\\nTrying to find \\n{}\\nFOUND\".format(seg))\n",
    "        pp_id=0\n",
    "        for p, pp in enumerate(pps):\n",
    "            if len(pp) == 0 or len(seg) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                if pp.find(seg) >= 0:\n",
    "                    #print(\"PERFECT MATCH!!!!!!!!!!!!\")\n",
    "                    start = pp.find(seg)\n",
    "                    return start, start+len(seg), (start+len(seg)), -1, -1, p\n",
    "                a_ = pairwise2.align.globalms(seg, pp, 3, -.5, -.1, -0.1)[0]\n",
    "                # get std\n",
    "                score = a_.score\n",
    "                score /= len(pp)\n",
    "                matching = [0 if (a_.seqB[i] == '-') else 1 for i in range(len(a_.seqB))]\n",
    "                # get mean\n",
    "                res_id = [idx for idx, val in enumerate(matching) if val != 0]\n",
    "                res_arr = np.asarray(res_id)\n",
    "                std = np.std(res_arr)\n",
    "                if std < min_std:\n",
    "                    pp_id = 0\n",
    "                    min_std = std\n",
    "                    best_score = score\n",
    "                    mean_best = np.mean(res_arr)\n",
    "                    start_best = matching.index(1)\n",
    "                    end_best = len(matching) - matching[::-1].index(1)\n",
    "        # print(pps[pp_id][start_best:end_best])\n",
    "        if (start_best >= 0) & (min_std < max_std):\n",
    "            return start_best, end_best, mean_best, min_std, best_score, int(pp_id)\n",
    "        else:\n",
    "            return None, None, None, None, None, -1\n",
    "    cols = ['start', 'end', 'mean', 'std', 'score', 'pp_id']\n",
    "    cols = [section_name+'_'+x for x in cols]\n",
    "    df[cols] = df.apply(lambda x: align([x.pp_seqs, x[section_name+'_clean']], max_std, min_score), axis=1, result_type=\"expand\")\n",
    "    df = df.astype({section_name+'_pp_id': int})\n",
    "    return df\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "informal-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del complete_i \n",
    "complete_i = df_align_func(full_i, section_name='TM7')\n",
    "complete_i = df_align_func(complete_i, section_name='H8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "happy-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del complete_a\n",
    "complete_a = df_align_func(full_a, section_name='TM7')\n",
    "complete_a = df_align_func(complete_a, section_name='H8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "several-violin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_found_seg(df, section_name, filter_bad_aligns=False, max_diff=5):\n",
    "    def get_seg_seq(x):\n",
    "        seqs = x[0]\n",
    "        if x[1] == -1:\n",
    "            return ''\n",
    "        else:\n",
    "            seq_id = int(x[1])\n",
    "            start = int(x[2])\n",
    "            end = int(x[3])\n",
    "            return seqs[seq_id][start:end]\n",
    "    df = df[df[section_name+'_pp_id']!=-1]\n",
    "    df[[section_name + '_found', section_name + '_angles']] = df.apply(\n",
    "        lambda x: get_seg_seq([x.pp_seqs, x[section_name + '_pp_id'], x[section_name+'_start'], x[section_name+'_end']]), axis=1, result_type=\"expand\")\n",
    "    if filter_bad_aligns:\n",
    "        df = df[abs(df[section_name+'_clean'].map(len) - df[section_name+'_found'].map(len)) <= max_diff]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "chronic-violin",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-818bd1ecc6f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchained_assignment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# default='warn'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcomplete_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_found_seg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplete_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TM7'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mcomplete_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_found_seg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplete_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'H8'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcomplete_a\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_found_seg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomplete_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TM7'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-41c6439e6132>\u001b[0m in \u001b[0;36mtest_found_seg\u001b[1;34m(df, section_name, filter_bad_aligns, max_diff)\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mseqs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msection_name\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'_pp_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     df[[section_name + '_found', section_name + '_angles']] = df.apply(\n\u001b[0m\u001b[0;32m     13\u001b[0m         lambda x: get_seg_seq([x.pp_seqs, x[section_name + '_pp_id'], x[section_name+'_start'], x[section_name+'_end']]), axis=1, result_type=\"expand\")\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilter_bad_aligns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3158\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3159\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3160\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3161\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3162\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3193\u001b[0m                 )[1]\n\u001b[0;32m   3194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3195\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"iloc\"\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m         \u001b[0miloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1633\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1634\u001b[0m             \u001b[1;31m# We have to operate column-wise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1635\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1637\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1709\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1710\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1711\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m   1712\u001b[0m                     \u001b[1;34m\"Must have equal len keys and value \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m                     \u001b[1;34m\"when setting with an iterable\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "complete_i = test_found_seg(complete_i, 'TM7', True)\n",
    "complete_i = test_found_seg(complete_i, 'H8', True)\n",
    "complete_a = test_found_seg(complete_a, 'TM7', True)\n",
    "complete_a = test_found_seg(complete_a, 'H8', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-essex",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_i[['TM7_clean', 'TM7_found', 'H8_clean', 'H8_found']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "wired-kansas",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['TM7_found', 'H8_found'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-fe5f9c593043>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcomplete_a\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'TM7_clean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TM7_found'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'H8_clean'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'H8_found'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3028\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3029\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3030\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3032\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[1;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1264\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1266\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\mt\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[1;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m                 \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1316\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{not_found} not in index\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['TM7_found', 'H8_found'] not in index\""
     ]
    }
   ],
   "source": [
    "complete_a[['TM7_clean', 'TM7_found', 'H8_clean', 'H8_found']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "limited-hopkins",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_by_pos(df, pos_l=7.48, pos_r=8.51, clean=True):\n",
    "    def mask_seq(seq, mask):\n",
    "        out=''.join([s for s, m in zip(seq, mask) if m])\n",
    "        return [out]\n",
    "    def clean_pos(x):\n",
    "        return np.asarray([float(y[:4]) for y in x])\n",
    "    def mask_l(pos_l, x):\n",
    "        y = x[1][:len(x[0])]\n",
    "        mask = y>=pos_l\n",
    "        output=mask_seq(list(x[0]), list(mask))\n",
    "        return output, list(y[mask])\n",
    "    def mask_r(pos_r, x):\n",
    "        y = x[1][-len(x[0]):]\n",
    "        mask = y<=pos_r\n",
    "        output=mask_seq(list(x[0]), list(mask))\n",
    "        return output, list(y[mask])\n",
    "    if clean:\n",
    "        df['roi_pos'] = df.apply(lambda x: clean_pos(x.roi_pos), axis=1)\n",
    "    df[['TM7_target']] = df.apply(lambda x: mask_l(pos_l, [x.TM7_clean, x.roi_pos]), axis=1)\n",
    "    df[['H8_target']] = df.apply(lambda x: mask_r(pos_r, [x.H8_clean, x.roi_pos]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "foster-internet",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_i = get_targets_by_pos(complete_i, clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "greek-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_a = get_targets_by_pos(complete_a, clean=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "based-tract",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_i.psi_phi.iloc[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "documented-wagner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_angles(df, section_name):\n",
    "    def get_target_angles_(x):\n",
    "        pp_id = x[2]\n",
    "        angles = np.asarray(x[0][pp_id])\n",
    "        pp_seqs = x[1]\n",
    "        section_seq = pp_seqs[pp_id]\n",
    "        target_seq = x[3][0]\n",
    "        target_pos = x[3][1]\n",
    "        section_start = x[4]\n",
    "        section_end = x[5]\n",
    "        start = section_seq.find(target_seq[0])\n",
    "        end = start + len(target_seq[0])\n",
    "        return [target_seq, angles[start:end, :], target_pos]\n",
    "    df[section_name + '_target_angles'] = df.apply(lambda x: get_target_angles_([\n",
    "        x['psi_phi'],\n",
    "        x.pp_seqs,\n",
    "        x[section_name + '_pp_id'],\n",
    "        x[section_name + '_target'],\n",
    "        x[section_name+'_start'],\n",
    "        x[section_name+'_end']]),\n",
    "        axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "acquired-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_i = get_target_angles(complete_i, 'TM7')\n",
    "complete_i = get_target_angles(complete_i, 'H8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "multiple-landscape",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['LDPWIYILL'],\n",
       " array([[-1.3880771959067728, -0.5013849000665204],\n",
       "        [-1.046958965744422, -0.8883325376646591],\n",
       "        [-1.30664651603418, -0.5113572376980487],\n",
       "        [-1.22612579253683, -0.171989340324696],\n",
       "        [-1.1656019886667546, -0.6373626682953057],\n",
       "        [-1.5246754335373278, -0.5551059893863106],\n",
       "        [-1.178506023967218, -0.832747541419319],\n",
       "        [-1.3019040003728701, -0.5800264650121992],\n",
       "        [-1.6707972050059432, 0.6149350166201752]], dtype=object),\n",
       " [7.48, 7.49, 7.5, 7.51, 7.52, 7.53, 7.54, 7.55, 7.56]]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_i['TM7_target_angles'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "trying-photography",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['RKTVL'],\n",
       " array([[-0.9524743459344447, 2.8474735396439192],\n",
       "        [-0.9559122475543391, -0.7195193127143276],\n",
       "        [-1.223993907049586, -0.9234687456014833],\n",
       "        [-1.1253329590679622, -0.8797414726677569],\n",
       "        [-1.1079845424476868, -0.6839595178493582]], dtype=object),\n",
       " [8.47, 8.48, 8.49, 8.5, 8.51]]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_i['H8_target_angles'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fundamental-garden",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     [[RKTVL], [[-0.9524743459344447, 2.84747353964...\n",
       "5     [[SPDFR], [[-1.2792596719931222, 2.04956651110...\n",
       "6     [[SPDFR], [[-1.3220617267255783, 2.30238146122...\n",
       "7     [[SPDFR], [[-1.3141165648849489, 2.22033663605...\n",
       "8     [[SPDFR], [[-1.1933672504497996, 2.14511919469...\n",
       "                            ...                        \n",
       "68    [[IREFR], [[-2.286104370389607, 1.971109284115...\n",
       "69    [[IREFR], [[-2.1130841466467487, 1.93437318688...\n",
       "70    [[IREFR], [[-2.384400483466984, 1.971324607588...\n",
       "71    [[IREFR], [[-2.116122687233844, 1.916615445091...\n",
       "72    [[SPDFR], [[-1.1990518911799755, 2.19484783121...\n",
       "Name: H8_target_angles, Length: 66, dtype: object"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_i['H8_target_angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "purple-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_a = get_target_angles(complete_a, 'TM7')\n",
    "complete_a = get_target_angles(complete_a, 'H8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "understood-soldier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[VFR], [[-1.7526860032099898, -0.533315811249...\n",
       "1          [[DQRYT], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "2     [[], [], [7.35, 7.36, 7.37, 7.38, 7.39, 7.4, 7...\n",
       "3          [[NKEDL], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "4          [[SPDFR], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "5     [[], [], [7.34, 7.35, 7.36, 7.37, 7.38, 7.39, ...\n",
       "8          [[SPDFR], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "9          [[SPDFR], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "10         [[SPDFR], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "11         [[SPDFR], [], [8.47, 8.48, 8.49, 8.5, 8.51]]\n",
       "12    [[RKTVL], [[1.2883155168696918, -0.37939638826...\n",
       "Name: H8_target_angles, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_a['H8_target_angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "vertical-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     [[LDPWIYILL], [[-1.3880771959067728, -0.501384...\n",
       "5     [[FNPLIYCR], [[-1.5192121407400672, -0.7723218...\n",
       "6     [[FNPLIYCR], [[-1.4699625030918857, -0.6861907...\n",
       "7     [[FNPLIYCR], [[-1.4882763672206794, -0.6864074...\n",
       "8     [[FNPLIYCR], [[-1.4644683129257023, -0.7221155...\n",
       "                            ...                        \n",
       "68    [[VNPFIYAYR], [[-1.4042951848819365, -0.545188...\n",
       "69    [[VNPFIYAYR], [[-1.4178968663221145, -0.550378...\n",
       "70    [[VNPFIYAYR], [[-1.2589065253456386, -0.725931...\n",
       "71    [[VNPFIYAYR], [[-1.3638430121916554, -0.545401...\n",
       "72    [[FNPLIYCR], [[-1.2994221734753457, -0.7429547...\n",
       "Name: TM7_target_angles, Length: 66, dtype: object"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_i['TM7_target_angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "identical-grave",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     [[CNPVIYSLS], [[-1.1584694927608943, -0.463390...\n",
       "1     [[AVPVAMGLG], [], [7.48, 7.49, 7.5, 7.51, 7.52...\n",
       "2     [[AVPVAMGLG], [], [7.48, 7.49, 7.5, 7.51, 7.52...\n",
       "3     [[VNPFIYAYR], [[-1.40906097097105, -0.36401686...\n",
       "4     [[FNPLIYCR], [], [7.48, 7.49, 7.5, 7.51, 7.52,...\n",
       "5     [[AVPVAMG], [[-1.5366409652513986, -0.33703889...\n",
       "8     [[FNPLIY], [], [7.48, 7.49, 7.5, 7.51, 7.52, 7...\n",
       "9     [[FNPLIY], [], [7.48, 7.49, 7.5, 7.51, 7.52, 7...\n",
       "10    [[FNPLIY], [], [7.48, 7.49, 7.5, 7.51, 7.52, 7...\n",
       "11    [[FNPLIYC], [], [7.48, 7.49, 7.5, 7.51, 7.52, ...\n",
       "12    [[LDPWIYILL], [[-1.709451176344388, -0.0760847...\n",
       "Name: TM7_target_angles, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_a['TM7_target_angles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "different-resistance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "medieval-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_a.to_pickle('a_angles.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-continent",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_i.to_pickle('i_angles.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-slope",
   "metadata": {},
   "source": [
    "# Target Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_data(full: pd.DataFrame, max_std_alignment=None, elongate=True, padding_r=5, target='NPFIY', filter_bad_checks=False):\n",
    "    # get alignment: https://towardsdatascience.com/pairwise-sequence-alignment-using-biopython-d1a9d0ba861f\n",
    "    complete = get_align_dict(full)\n",
    "    # filter by maximum alignment standard deviation (basically if it is wrong)\n",
    "    if max_std_alignment!=None:\n",
    "        complete = complete[complete['std'] < max_std_alignment]\n",
    "    # replace the TM7 with an elongated version\n",
    "    if elongate:\n",
    "        complete['TM7_found'] = complete.apply(lambda x: x.full_prot_seq[x.start:x.end+padding_r], axis=1)\n",
    "        if filter_bad_checks:\n",
    "            max_diff = 15  # maximum difference in sequence lengths between detected and true TM7 region\n",
    "            complete = complete[complete['TM7_combined'].map(len) + max_diff - complete['TM7_found'].map(len) >= 0]\n",
    "    # extract target sequence from the TM7\n",
    "    if target_by_str!=None:\n",
    "        complete['target_by_str'] = complete.apply(lambda x: align_seg_to_seq([x.TM7_combined, target, x.PDB]), axis=1)\n",
    "    if target_by_pos!=None:\n",
    "        complete['target_by_pos'] = complete.apply(lambda x: align_seg_to_seq([x.TM7_combined, target, x.PDB]), axis=1)\n",
    "    return complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-credit",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "insured-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-berlin",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-selection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-swift",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "complete_a = complete_data(full_a, target='NPFIY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-spell",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(full_a))\n",
    "print(len(complete_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-atlanta",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(complete_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-green",
   "metadata": {},
   "source": [
    "# Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quick-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_i = complete_data(full_i, max_std_alignment=None, elongate=True, padding_r=5, target='NPFIY', filter_bad_checks=True)\n",
    "# this is the part where we want to increase the target range (since it is inconsistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(complete_i[['TM7_combined', 'TM7_found']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-attitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_a = complete_data(full_a, max_std_alignment=None, elongate=True, padding_r=5, target='NPFIY', filter_bad_checks=True)\n",
    "# this is the part where we want to increase the target range (since it is inconsistent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "current-muslim",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(complete_a[['TM7_combined', 'TM7_found']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-convergence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disp3(complete_i['start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-harris",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# len(complete_i[complete_i['std'] < 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-brave",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "len(complete_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-blair",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fix that number ~ we have 73 proteins in the full datatable but end up with 87 \n",
    "# after the segments alignment is complete (unfiltered)\n",
    "# disp3(complete_i['TM7_combined'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-nylon",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(complete_i[['PDB', 'TM7_combined', 'target_wrt_tm7']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brave-keeping",
   "metadata": {},
   "source": [
    "# Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrow-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'NPLIY'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_df(complete: pd.DataFrame, target='NPXXY', valid=True):\n",
    "    def sum_start(a, b):\n",
    "        return a + b[0]\n",
    "    def sum_end(a, b):\n",
    "        return a + b[1]\n",
    "    def extend(ls):\n",
    "        is_list = isinstance(ls[0], list)\n",
    "        for i, l in enumerate(ls):\n",
    "            if is_list & i == 0:\n",
    "                out = l\n",
    "            elif is_list:\n",
    "                out.extend(l)\n",
    "            else:\n",
    "                return ls\n",
    "        return out\n",
    "    def clean_pps(x):\n",
    "        return ast.literal_eval(x.replace('Seq', '').replace('(', '').replace(')', ''))\n",
    "    target_df = complete[['PDB', 'uniprot(gene)', 'Resolution', 'PDB date', \\\n",
    "                          'TM7_found', 'score', 'prot_len', 'full_prot_seq', 'start']].copy()\n",
    "    target_df['pp_seqs'] = complete.apply(lambda x: clean_pps(x.pp_seqs), axis=1).copy()\n",
    "    target_df['pp_seq_lens'] = target_df.apply(lambda x: [len(y) for y in x.pp_seqs], axis=1).copy()\n",
    "    # target_df.loc[:, 'target_seq'] = target\n",
    "    target_df['start_absolute'] = complete.apply(lambda x: sum_start(x.start, x.target_wrt_tm7), axis=1).copy()\n",
    "    target_df['end_absolute'] = complete.apply(lambda x: sum_end(x.start, x.target_wrt_tm7), axis=1).copy()\n",
    "    target_df['start'] = complete['target_wrt_tm7'].apply(lambda x: x[0]).copy()\n",
    "    target_df['end'] = complete['target_wrt_tm7'].apply(lambda x: x[1]).copy()\n",
    "    target_df['full_aligned_seg'] = target_df.apply(lambda x: x.full_prot_seq[x.start_absolute:x.end_absolute], axis=1)\n",
    "    target_df['TM7_aligned_seg'] = target_df.apply(lambda x: x.TM7_found[x.start:x.end], axis=1)\n",
    "    target_df['psi_phi'] = complete.apply(lambda x: extend(ast.literal_eval(x.psi_phi)), axis=1)\n",
    "    if valid:\n",
    "        target_df['target_angles'] = target_df.apply(lambda x: x.psi_phi[x.start_absolute:x.end_absolute], axis=1)\n",
    "        target_df = target_df[target_df['full_aligned_seg']==target_df['TM7_aligned_seg']]\n",
    "        return target_df  # [len(target_df['target_angles']) >= len(target)]\n",
    "    else:\n",
    "        return target_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-aquatic",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_a = get_target_df(complete_a, target, valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_a.to_csv('valid_a.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_i = get_target_df(complete_i, target, valid=True)\n",
    "# Filter for proteins where the alignments match ~ indicates that angles are valid and the region is present\n",
    "# if only valids we compare if the full aligned segment withthe TM7 aligned segment\n",
    "valid_i.to_csv('valid_i.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-tattoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(valid_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp3(valid_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naked-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_a.target_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-locking",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(valid_i['target_angles'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-sharp",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(valid_a['target_angles'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "institutional-despite",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_i.to_csv('valid_i.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# j, o, u and x do not code for an amino acid (sometimes used to represent ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subsequent-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(valid_i[valid_i['full_aligned_seg']==valid_i['TM7_aligned_seg']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = valid_i[['prot_len', 'psi_phi']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "contrary-clearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "x['len_psi_phi'] = valid_i.apply(lambda x: len(x.psi_phi), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-portrait",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-portable",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# match each of the active complexes to all the inactive ones (based on the uniprot genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-poker",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# interaction dataframe\n",
    "\n",
    "interaction_df = pd.DataFrame(columns=['PDB_active', 'PDB_inactive', 'phi_psi_active', 'phi_psi_inactive', 'delta_phi_psi'])\n",
    "# this should be done here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-prince",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composed-clearing",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-billion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "higher-consistency",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-apple",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extreme-consensus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-mandate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
