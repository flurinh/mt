{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accredited-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacterial-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # Transfer data object to GPU.\n",
    "    device = torch.device('cuda')\n",
    "    data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binding-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "automatic-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = QM9(root='/tmp/QM9')\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aging-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.delta_net import *\n",
    "from neuralnet.egnn_sparse import *\n",
    "from neuralnet.net_utils import *\n",
    "from neuralnet.h5_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "precise-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "eg = dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "preliminary-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_attr=[8, 4], edge_index=[2, 8], idx=[1], name=\"gdb_1\", pos=[5, 3], x=[5, 11], y=[1, 19], z=[5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "altered-spiritual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.edge_attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "flush-march",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 6., 0., 0., 0., 0., 4.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "preceding-tracker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0.0000,    13.2100,   -10.5499,     3.1865,    13.7363,    35.3641,\n",
       "            1.2177, -1101.4877, -1101.4095, -1101.3839, -1102.0228,     6.4690,\n",
       "          -17.1722,   -17.2868,   -17.3897,   -16.1519,   157.7118,   157.7100,\n",
       "          157.7070])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.y[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "conceptual-mention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eg.z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "irish-holmes",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "express-arkansas",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:00, 69.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-54.0674)\n",
      "tensor(-50.3337)\n",
      "tensor(-48.9046)\n",
      "tensor(-47.9501)\n",
      "tensor(-41.9754)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [00:00, 144.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-40.8855)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "125it [00:00, 144.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-32.9630)\n",
      "tensor(-23.6567)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "346it [00:02, 143.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-13.1353)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [00:02, 140.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-12.0821)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:15, 133.10it/s]\n"
     ]
    }
   ],
   "source": [
    "mean_list = []\n",
    "max_ = -100\n",
    "min_ = 100\n",
    "for b,  batch in tqdm(enumerate(loader)):\n",
    "    target = batch.y[:, 13]\n",
    "    if torch.max(target) > max_:\n",
    "        print(torch.max(target))\n",
    "        max_ = torch.max(target)\n",
    "    if torch.min(target) < min_:\n",
    "        min_ = torch.min(target)\n",
    "    mean_ = torch.mean(target)\n",
    "    if b == 2000:\n",
    "        break\n",
    "    else:\n",
    "        mean_list.append(mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "differential-cleaners",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-76.582985\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.mean(mean_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "alike-share",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-12.0821)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "tight-combining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-113.8919)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "empty-crawford",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(1.2187),\n",
       " tensor(1.1581),\n",
       " tensor(1.1241),\n",
       " tensor(1.1672),\n",
       " tensor(1.0917),\n",
       " tensor(1.1163),\n",
       " tensor(1.1052),\n",
       " tensor(1.0962),\n",
       " tensor(1.0534),\n",
       " tensor(1.0792),\n",
       " tensor(1.0830),\n",
       " tensor(1.1247),\n",
       " tensor(1.1574),\n",
       " tensor(1.0768),\n",
       " tensor(1.1279),\n",
       " tensor(1.0601),\n",
       " tensor(1.0878),\n",
       " tensor(1.0366),\n",
       " tensor(1.0207),\n",
       " tensor(1.2083),\n",
       " tensor(1.1692),\n",
       " tensor(1.1099),\n",
       " tensor(0.9898),\n",
       " tensor(1.1252),\n",
       " tensor(1.1317),\n",
       " tensor(1.0764),\n",
       " tensor(1.0796),\n",
       " tensor(1.0839),\n",
       " tensor(1.1052),\n",
       " tensor(1.0649),\n",
       " tensor(1.0269),\n",
       " tensor(1.2034),\n",
       " tensor(1.1840),\n",
       " tensor(0.9803),\n",
       " tensor(1.1180),\n",
       " tensor(1.0825),\n",
       " tensor(1.1559),\n",
       " tensor(1.1311),\n",
       " tensor(1.1464),\n",
       " tensor(1.0367),\n",
       " tensor(1.1307),\n",
       " tensor(1.1210),\n",
       " tensor(1.0741),\n",
       " tensor(1.1980),\n",
       " tensor(1.0667),\n",
       " tensor(1.0407),\n",
       " tensor(1.0760),\n",
       " tensor(1.1333),\n",
       " tensor(1.1081),\n",
       " tensor(1.0931),\n",
       " tensor(1.1396),\n",
       " tensor(1.0923),\n",
       " tensor(1.1448),\n",
       " tensor(1.1181),\n",
       " tensor(1.0909),\n",
       " tensor(1.1402),\n",
       " tensor(1.1006),\n",
       " tensor(1.1395),\n",
       " tensor(1.1506),\n",
       " tensor(1.1169),\n",
       " tensor(1.1198),\n",
       " tensor(1.1096),\n",
       " tensor(0.9816),\n",
       " tensor(1.0617),\n",
       " tensor(1.2127),\n",
       " tensor(1.1078),\n",
       " tensor(1.0999),\n",
       " tensor(1.1692),\n",
       " tensor(1.1215),\n",
       " tensor(1.2153),\n",
       " tensor(1.1736),\n",
       " tensor(1.0873),\n",
       " tensor(1.0793),\n",
       " tensor(1.0781),\n",
       " tensor(1.1754),\n",
       " tensor(1.0576),\n",
       " tensor(1.0882),\n",
       " tensor(1.1617),\n",
       " tensor(1.1021),\n",
       " tensor(1.1655),\n",
       " tensor(1.0904),\n",
       " tensor(1.0055),\n",
       " tensor(0.9789),\n",
       " tensor(1.0934),\n",
       " tensor(1.1372),\n",
       " tensor(1.1496),\n",
       " tensor(1.1416),\n",
       " tensor(1.1194),\n",
       " tensor(1.1266),\n",
       " tensor(1.2027),\n",
       " tensor(1.1128),\n",
       " tensor(1.1509),\n",
       " tensor(1.1541),\n",
       " tensor(1.1250),\n",
       " tensor(1.0983),\n",
       " tensor(1.0826),\n",
       " tensor(1.1496),\n",
       " tensor(1.0547),\n",
       " tensor(1.3497),\n",
       " tensor(1.0908),\n",
       " tensor(1.1674),\n",
       " tensor(1.0674),\n",
       " tensor(1.1242),\n",
       " tensor(1.1835),\n",
       " tensor(1.1251),\n",
       " tensor(1.0792),\n",
       " tensor(1.0990),\n",
       " tensor(1.1303),\n",
       " tensor(1.0626),\n",
       " tensor(1.1291),\n",
       " tensor(1.0377),\n",
       " tensor(1.0978),\n",
       " tensor(1.1288),\n",
       " tensor(1.1352),\n",
       " tensor(1.3338),\n",
       " tensor(1.1390),\n",
       " tensor(1.0758),\n",
       " tensor(1.0569),\n",
       " tensor(1.1006),\n",
       " tensor(1.1754),\n",
       " tensor(1.1625),\n",
       " tensor(1.1862),\n",
       " tensor(1.1601),\n",
       " tensor(1.1711),\n",
       " tensor(1.1285),\n",
       " tensor(1.0913),\n",
       " tensor(1.1565),\n",
       " tensor(1.1016),\n",
       " tensor(1.0104),\n",
       " tensor(1.1239),\n",
       " tensor(1.1683),\n",
       " tensor(1.0917),\n",
       " tensor(1.0843),\n",
       " tensor(1.1215),\n",
       " tensor(1.1525),\n",
       " tensor(1.0299),\n",
       " tensor(1.0196),\n",
       " tensor(1.0204),\n",
       " tensor(1.1179),\n",
       " tensor(1.0537),\n",
       " tensor(1.0594),\n",
       " tensor(1.1842),\n",
       " tensor(1.0790),\n",
       " tensor(1.1174),\n",
       " tensor(1.2244),\n",
       " tensor(1.1153),\n",
       " tensor(1.1285),\n",
       " tensor(1.1100),\n",
       " tensor(1.1163),\n",
       " tensor(1.1913),\n",
       " tensor(1.0955),\n",
       " tensor(1.1035),\n",
       " tensor(1.1170),\n",
       " tensor(1.1186),\n",
       " tensor(1.2217),\n",
       " tensor(1.2093),\n",
       " tensor(1.2109),\n",
       " tensor(1.1867),\n",
       " tensor(1.0798),\n",
       " tensor(1.1539),\n",
       " tensor(1.1743),\n",
       " tensor(1.1409),\n",
       " tensor(1.0511),\n",
       " tensor(1.0664),\n",
       " tensor(1.1006),\n",
       " tensor(0.9707),\n",
       " tensor(1.0759),\n",
       " tensor(1.0827),\n",
       " tensor(1.2053),\n",
       " tensor(1.1356),\n",
       " tensor(1.1136),\n",
       " tensor(1.0609),\n",
       " tensor(1.0837),\n",
       " tensor(1.0928),\n",
       " tensor(1.1638),\n",
       " tensor(1.2037),\n",
       " tensor(1.1594),\n",
       " tensor(1.1416),\n",
       " tensor(1.1136),\n",
       " tensor(1.2491),\n",
       " tensor(1.2081),\n",
       " tensor(1.0478),\n",
       " tensor(1.1325),\n",
       " tensor(1.1359),\n",
       " tensor(1.0671),\n",
       " tensor(1.0299),\n",
       " tensor(1.0502),\n",
       " tensor(1.0850),\n",
       " tensor(1.0620),\n",
       " tensor(1.1759),\n",
       " tensor(1.1479),\n",
       " tensor(1.1195),\n",
       " tensor(1.0633),\n",
       " tensor(1.1107),\n",
       " tensor(1.1495),\n",
       " tensor(1.0138),\n",
       " tensor(1.1864),\n",
       " tensor(1.2002),\n",
       " tensor(1.3172),\n",
       " tensor(1.0387)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "legislative-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5n =  H5Net(n_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "latin-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "modular-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 24.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "target: tensor([-0.6032])   <>   prediction: tensor([1.], grad_fn=<SelectBackward>)\n",
      "==============================================================\n",
      "mean batch loss:  tensor(0.1320, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "103it [00:05, 18.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1184, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [00:11, 16.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1368, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "303it [00:17, 17.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1628, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403it [00:23, 15.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1292, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [00:29, 18.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1326, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [00:35, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1321, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "703it [00:42, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1473, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "803it [00:49, 14.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1468, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "905it [00:55, 19.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1537, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1004it [01:00, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "target: tensor([-0.7855])   <>   prediction: tensor([1.], grad_fn=<SelectBackward>)\n",
      "==============================================================\n",
      "mean batch loss:  tensor(0.1389, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1105it [01:06, 19.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1503, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1203it [01:11, 17.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1390, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1304it [01:18, 17.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1406, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1404it [01:23, 17.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1436, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1503it [01:29, 18.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1508, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1604it [01:35, 19.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1167, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1704it [01:41, 18.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1204, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1804it [01:46, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1353, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1904it [01:52, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1306, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2003it [01:57, 17.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "target: tensor([-0.6701])   <>   prediction: tensor([1.], grad_fn=<SelectBackward>)\n",
      "==============================================================\n",
      "mean batch loss:  tensor(0.1302, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2103it [02:03, 18.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1414, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2203it [02:08, 17.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1373, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2302it [02:14, 10.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1551, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2402it [02:21, 11.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1714, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2504it [02:28, 15.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1220, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2605it [02:33, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1229, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2703it [02:39, 19.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1485, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2803it [02:45, 18.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1532, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2903it [02:51, 14.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1453, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3005it [02:57, 19.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "target: tensor([-0.6487])   <>   prediction: tensor([1.], grad_fn=<SelectBackward>)\n",
      "==============================================================\n",
      "mean batch loss:  tensor(0.1182, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3105it [03:02, 19.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1534, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3204it [03:07, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1464, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3304it [03:13, 18.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1315, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3404it [03:18, 19.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1365, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3504it [03:23, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1364, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3603it [03:29, 15.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1381, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3703it [03:35, 17.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1551, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3803it [03:40, 17.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1217, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3904it [03:46, 18.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean batch loss:  tensor(0.1261, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4004it [03:51, 19.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================================\n",
      "target: tensor([-0.6144])   <>   prediction: tensor([1.], grad_fn=<SelectBackward>)\n",
      "==============================================================\n",
      "mean batch loss:  tensor(0.1524, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4089it [03:57, 17.25it/s]\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(h5n.parameters(), lr=0.0000001)\n",
    "\n",
    "for b,  batch in tqdm(enumerate(loader)):\n",
    "    pred = h5n(batch)\n",
    "    target = batch.y[:, 13][:, None] / 120\n",
    "    loss = criterion(-1 * pred, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if b % 1000 == 0:\n",
    "        print(\"==============================================================\")\n",
    "        print(\"target: {}   <>   prediction: {}\".format(target[0], pred[0]))\n",
    "        print(\"==============================================================\")\n",
    "    if b % 100 == 0:\n",
    "        print(\"mean batch loss: \", torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-error",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "functioning-roots",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-french",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
