{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accredited-trouble",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                           [1, 0, 2, 1]], dtype=torch.long)\n",
    "x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bacterial-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 4], x=[3, 1])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mexican-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "binding-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pressed-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import QM9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "automatic-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "dataset = QM9(root='/tmp/QM9')\n",
    "\n",
    "validation_split = .2\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "batch_size = 16\n",
    "\n",
    "# Creating data indices for training and validation splits\n",
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if shuffle_dataset :\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "# Creating PT data samplers and loaders\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n",
    "validation_loader = DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aging-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralnet.delta_net import *\n",
    "from neuralnet.egnn_sparse import *\n",
    "from neuralnet.net_utils import *\n",
    "from neuralnet.h5_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "legislative-grocery",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5n = H5Net(n_outputs=1, aggr='add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "latin-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "#h5n.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f69735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'models/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a452f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H5Net(\n",
       "  (embedding): Embedding(5, 24)\n",
       "  (emb_ffl): Linear(in_features=24, out_features=24, bias=True)\n",
       "  (kernels): ModuleList(\n",
       "    (0): EGNN_sparse(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (edge_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (edge_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=57, out_features=114, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): SiLU()\n",
       "        (3): Linear(in_features=114, out_features=64, bias=True)\n",
       "        (4): SiLU()\n",
       "      )\n",
       "      (node_norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (node_norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=88, out_features=48, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): SiLU()\n",
       "        (3): Linear(in_features=48, out_features=24, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): EGNN_sparse(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (edge_norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (edge_norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (edge_mlp): Sequential(\n",
       "        (0): Linear(in_features=57, out_features=114, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): SiLU()\n",
       "        (3): Linear(in_features=114, out_features=64, bias=True)\n",
       "        (4): SiLU()\n",
       "      )\n",
       "      (node_norm1): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (node_norm2): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
       "      (node_mlp): Sequential(\n",
       "        (0): Linear(in_features=88, out_features=48, bias=True)\n",
       "        (1): Dropout(p=0.1, inplace=False)\n",
       "        (2): SiLU()\n",
       "        (3): Linear(in_features=48, out_features=24, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (ffnn): ModuleList(\n",
       "    (0): Linear(in_features=72, out_features=256, bias=True)\n",
       "    (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (3): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5n = H5Net(n_outputs=1, aggr='add')\n",
    "h5n.load_state_dict(torch.load(model_path + 'h5n.pth'))\n",
    "torch.cuda.empty_cache()\n",
    "h5n.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63767bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "modular-ceiling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAINING: mean epoch loss = 0.008161: : 6542it [01:21, 80.30it/s]\n",
      "VALIDATION: mean epoch loss = 0.003744: : 1636it [00:09, 171.12it/s]\n",
      "TRAINING: mean epoch loss = 0.002681: : 6542it [01:10, 92.90it/s]\n",
      "VALIDATION: mean epoch loss = 0.00227: : 1636it [00:07, 228.47it/s] \n",
      "TRAINING: mean epoch loss = 0.002101: : 6542it [01:09, 94.49it/s]\n",
      "VALIDATION: mean epoch loss = 0.002026: : 1636it [00:07, 227.90it/s]\n",
      "TRAINING: mean epoch loss = 0.002077: : 6542it [01:09, 94.20it/s]\n",
      "VALIDATION: mean epoch loss = 0.002061: : 1636it [00:07, 219.70it/s]\n",
      "TRAINING: mean epoch loss = 0.002307: : 6542it [01:08, 95.91it/s]\n",
      "VALIDATION: mean epoch loss = 0.002689: : 1636it [00:07, 231.22it/s]\n",
      "TRAINING: mean epoch loss = 0.002283: : 6542it [01:07, 96.26it/s]\n",
      "VALIDATION: mean epoch loss = 0.002047: : 1636it [00:07, 232.53it/s]\n",
      "TRAINING: mean epoch loss = 0.002217: : 6542it [01:08, 96.05it/s]\n",
      "VALIDATION: mean epoch loss = 0.00258: : 1636it [00:07, 232.07it/s] \n",
      "TRAINING: mean epoch loss = 0.002104: : 6542it [01:08, 96.02it/s]\n",
      "VALIDATION: mean epoch loss = 0.002102: : 1636it [00:07, 230.84it/s]\n",
      "TRAINING: mean epoch loss = 0.00196: : 6542it [01:11, 90.91it/s] \n",
      "VALIDATION: mean epoch loss = 0.001914: : 1636it [00:07, 211.90it/s]\n",
      "TRAINING: mean epoch loss = 0.001908: : 6542it [01:11, 91.33it/s]\n",
      "VALIDATION: mean epoch loss = 0.001926: : 1636it [00:07, 227.04it/s]\n",
      "TRAINING: mean epoch loss = 0.001902: : 6542it [01:09, 94.00it/s]\n",
      "VALIDATION: mean epoch loss = 0.00191: : 1636it [00:07, 226.79it/s] \n",
      "TRAINING: mean epoch loss = 0.001891: : 6542it [01:09, 93.49it/s]\n",
      "VALIDATION: mean epoch loss = 0.001898: : 1636it [00:07, 226.29it/s]\n",
      "TRAINING: mean epoch loss = 0.001887: : 6542it [01:10, 92.65it/s]\n",
      "VALIDATION: mean epoch loss = 0.001901: : 1636it [00:07, 209.85it/s]\n",
      "TRAINING: mean epoch loss = 0.001876: : 6542it [01:07, 96.32it/s]\n",
      "VALIDATION: mean epoch loss = 0.001903: : 1636it [00:07, 232.93it/s]\n",
      "TRAINING: mean epoch loss = 0.001879: : 6542it [01:07, 97.14it/s]\n",
      "VALIDATION: mean epoch loss = 0.001903: : 1636it [00:07, 233.10it/s]\n",
      "TRAINING: mean epoch loss = 0.001915: : 6542it [01:08, 96.17it/s]\n",
      "VALIDATION: mean epoch loss = 0.001968: : 1636it [00:07, 230.99it/s]\n",
      "TRAINING: mean epoch loss = 0.001886: : 6542it [01:07, 96.47it/s]\n",
      "VALIDATION: mean epoch loss = 0.001897: : 1636it [00:07, 231.48it/s]\n",
      "TRAINING: mean epoch loss = 0.001892: : 6542it [01:09, 94.80it/s]\n",
      "VALIDATION: mean epoch loss = 0.001978: : 1636it [00:07, 231.25it/s]\n",
      "TRAINING: mean epoch loss = 0.00196: : 6542it [01:11, 91.60it/s] \n",
      "VALIDATION: mean epoch loss = 0.00213: : 1636it [00:07, 214.48it/s] \n",
      "TRAINING: mean epoch loss = 0.001988: : 6542it [01:09, 93.96it/s]\n",
      "VALIDATION: mean epoch loss = 0.002057: : 1636it [00:07, 215.22it/s]\n",
      "TRAINING: mean epoch loss = 0.001943: : 6542it [01:08, 95.95it/s]\n",
      "VALIDATION: mean epoch loss = 0.001968: : 1636it [00:06, 234.50it/s]\n",
      "TRAINING: mean epoch loss = 0.001896: : 6542it [01:07, 96.61it/s]\n",
      "VALIDATION: mean epoch loss = 0.001856: : 1636it [00:06, 234.00it/s]\n",
      "TRAINING: mean epoch loss = 0.001851: : 6542it [01:11, 92.09it/s]\n",
      "VALIDATION: mean epoch loss = 0.001886: : 1636it [00:06, 234.30it/s]\n",
      "TRAINING: mean epoch loss = 0.001828: : 6542it [01:07, 96.52it/s]\n",
      "VALIDATION: mean epoch loss = 0.001839: : 1636it [00:08, 201.53it/s]\n",
      "TRAINING: mean epoch loss = 0.001808: : 6542it [01:16, 85.58it/s]\n",
      "VALIDATION: mean epoch loss = 0.001843: : 1636it [00:07, 218.17it/s]\n",
      "TRAINING: mean epoch loss = 0.001805: : 6542it [01:08, 94.96it/s]\n",
      "VALIDATION: mean epoch loss = 0.0018: : 1636it [00:07, 229.82it/s]  \n",
      "TRAINING: mean epoch loss = 0.001781: : 6542it [01:08, 95.22it/s]\n",
      "VALIDATION: mean epoch loss = 0.001782: : 1636it [00:07, 231.38it/s]\n",
      "TRAINING: mean epoch loss = 0.001773: : 6542it [01:08, 95.72it/s]\n",
      "VALIDATION: mean epoch loss = 0.001807: : 1636it [00:07, 232.10it/s]\n",
      "TRAINING: mean epoch loss = 0.001777: : 6542it [01:07, 97.14it/s]\n",
      "VALIDATION: mean epoch loss = 0.001819: : 1636it [00:07, 232.66it/s]\n",
      "TRAINING: mean epoch loss = 0.001779: : 6542it [01:07, 97.24it/s]\n",
      "VALIDATION: mean epoch loss = 0.001845: : 1636it [00:07, 233.03it/s]\n",
      "TRAINING: mean epoch loss = 0.001781: : 6542it [01:08, 95.11it/s]\n",
      "VALIDATION: mean epoch loss = 0.001764: : 1636it [00:07, 220.20it/s]\n",
      "TRAINING: mean epoch loss = 0.001773: : 6542it [01:08, 95.91it/s]\n",
      "VALIDATION: mean epoch loss = 0.001786: : 1636it [00:07, 221.18it/s]\n",
      "TRAINING: mean epoch loss = 0.001762: : 6542it [01:08, 96.05it/s]\n",
      "VALIDATION: mean epoch loss = 0.001774: : 1636it [00:07, 232.10it/s]\n",
      "TRAINING: mean epoch loss = 0.001745: : 6542it [01:07, 96.33it/s]\n",
      "VALIDATION: mean epoch loss = 0.001785: : 1636it [00:07, 229.76it/s]\n",
      "TRAINING: mean epoch loss = 0.001748: : 6542it [01:07, 96.64it/s]\n",
      "VALIDATION: mean epoch loss = 0.001772: : 1636it [00:07, 231.51it/s]\n",
      "TRAINING: mean epoch loss = 0.001742: : 6542it [01:08, 95.02it/s]\n",
      "VALIDATION: mean epoch loss = 0.001772: : 1636it [00:07, 232.80it/s]\n",
      "TRAINING: mean epoch loss = 0.001745: : 6542it [01:08, 96.05it/s]\n",
      "VALIDATION: mean epoch loss = 0.001767: : 1636it [00:07, 219.75it/s]\n",
      "TRAINING: mean epoch loss = 0.001769: : 6542it [01:08, 95.73it/s]\n",
      "VALIDATION: mean epoch loss = 0.001756: : 1636it [00:07, 230.44it/s]\n",
      "TRAINING: mean epoch loss = 0.001747: : 6542it [01:08, 95.99it/s]\n",
      "VALIDATION: mean epoch loss = 0.001786: : 1636it [00:07, 231.74it/s]\n",
      "TRAINING: mean epoch loss = 0.001748: : 6542it [01:07, 96.49it/s]\n",
      "VALIDATION: mean epoch loss = 0.00177: : 1636it [00:07, 232.20it/s] \n",
      "TRAINING: mean epoch loss = 0.001729: : 6542it [01:07, 96.22it/s]\n",
      "VALIDATION: mean epoch loss = 0.001756: : 1636it [00:07, 232.43it/s]\n",
      "TRAINING: mean epoch loss = 0.001738: : 6542it [01:07, 96.72it/s]\n",
      "VALIDATION: mean epoch loss = 0.001756: : 1636it [00:07, 231.71it/s]\n",
      "TRAINING: mean epoch loss = 0.001738: : 6542it [01:07, 97.08it/s]\n",
      "VALIDATION: mean epoch loss = 0.001755: : 1636it [00:07, 220.70it/s]\n",
      "TRAINING: mean epoch loss = 0.001737: : 6542it [01:07, 97.42it/s]\n",
      "VALIDATION: mean epoch loss = 0.001744: : 1636it [00:07, 232.23it/s]\n",
      "TRAINING: mean epoch loss = 0.001729: : 6542it [01:07, 97.03it/s]\n",
      "VALIDATION: mean epoch loss = 0.001811: : 1636it [00:07, 230.21it/s]\n",
      "TRAINING: mean epoch loss = 0.00172: : 6542it [01:07, 96.44it/s] \n",
      "VALIDATION: mean epoch loss = 0.001743: : 1636it [00:07, 228.86it/s]\n",
      "TRAINING: mean epoch loss = 0.001721: : 6542it [01:08, 95.49it/s]\n",
      "VALIDATION: mean epoch loss = 0.00173: : 1636it [00:07, 226.29it/s] \n",
      "TRAINING: mean epoch loss = 0.001704: : 6542it [01:08, 96.11it/s]\n",
      "VALIDATION: mean epoch loss = 0.001722: : 1636it [00:07, 232.70it/s]\n",
      "TRAINING: mean epoch loss = 0.001704: : 6542it [01:07, 96.91it/s]\n",
      "VALIDATION: mean epoch loss = 0.001752: : 1636it [00:07, 220.73it/s]\n",
      "TRAINING: mean epoch loss = 0.001712: : 6542it [01:07, 97.21it/s]\n",
      "VALIDATION: mean epoch loss = 0.001737: : 1636it [00:07, 226.89it/s]\n",
      "TRAINING: mean epoch loss = 0.001703: : 6542it [01:08, 96.16it/s]\n",
      "VALIDATION: mean epoch loss = 0.001745: : 1636it [00:07, 232.40it/s]\n",
      "TRAINING: mean epoch loss = 0.001695: : 6542it [01:07, 96.49it/s]\n",
      "VALIDATION: mean epoch loss = 0.001724: : 1636it [00:07, 232.14it/s]\n",
      "TRAINING: mean epoch loss = 0.001692: : 6542it [01:08, 96.16it/s]\n",
      "VALIDATION: mean epoch loss = 0.001709: : 1636it [00:07, 232.90it/s]\n",
      "TRAINING: mean epoch loss = 0.001694: : 6542it [01:07, 97.16it/s]\n",
      "VALIDATION: mean epoch loss = 0.001716: : 1636it [00:07, 232.40it/s]\n",
      "TRAINING: mean epoch loss = 0.001691: : 6542it [01:07, 96.41it/s]\n",
      "VALIDATION: mean epoch loss = 0.001714: : 1636it [00:07, 221.03it/s]\n",
      "TRAINING: mean epoch loss = 0.001688: : 6542it [01:07, 96.50it/s]\n",
      "VALIDATION: mean epoch loss = 0.001726: : 1636it [00:07, 230.79it/s]\n",
      "TRAINING: mean epoch loss = 0.001687: : 6542it [01:07, 96.45it/s]\n",
      "VALIDATION: mean epoch loss = 0.001702: : 1636it [00:07, 229.27it/s]\n",
      "TRAINING: mean epoch loss = 0.00169: : 6542it [01:07, 96.51it/s] \n",
      "VALIDATION: mean epoch loss = 0.00172: : 1636it [00:07, 232.33it/s] \n",
      "TRAINING: mean epoch loss = 0.001684: : 6542it [01:07, 97.33it/s]\n",
      "VALIDATION: mean epoch loss = 0.001699: : 1636it [00:07, 232.14it/s]\n",
      "TRAINING: mean epoch loss = 0.001691: : 6542it [01:07, 97.12it/s]\n",
      "VALIDATION: mean epoch loss = 0.001708: : 1636it [00:07, 232.60it/s]\n",
      "TRAINING: mean epoch loss = 0.001684: : 6542it [01:07, 96.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "VALIDATION: mean epoch loss = 0.001697: : 1636it [00:07, 220.17it/s]\n",
      "TRAINING: mean epoch loss = 0.001685: : 6542it [01:07, 96.58it/s]\n",
      "VALIDATION: mean epoch loss = 0.001695: : 1636it [00:07, 232.00it/s]\n",
      "TRAINING: mean epoch loss = 0.00169: : 6542it [01:08, 96.17it/s] \n",
      "VALIDATION: mean epoch loss = 0.001716: : 1636it [00:07, 230.96it/s]\n",
      "TRAINING: mean epoch loss = 0.001682: : 6542it [01:08, 96.05it/s]\n",
      "VALIDATION: mean epoch loss = 0.001694: : 1636it [00:07, 231.54it/s]\n",
      "TRAINING: mean epoch loss = 0.001682: : 6542it [01:08, 96.08it/s]\n",
      "VALIDATION: mean epoch loss = 0.001707: : 1636it [00:07, 231.77it/s]\n",
      "TRAINING: mean epoch loss = 0.001682: : 6542it [01:07, 96.85it/s]\n",
      "VALIDATION: mean epoch loss = 0.001694: : 1636it [00:07, 232.10it/s]\n",
      "TRAINING: mean epoch loss = 0.001677: : 6542it [01:07, 97.10it/s]\n",
      "VALIDATION: mean epoch loss = 0.001704: : 1636it [00:07, 221.06it/s]\n",
      "TRAINING: mean epoch loss = 0.001675: : 6542it [01:07, 97.33it/s]\n",
      "VALIDATION: mean epoch loss = 0.001711: : 1636it [00:07, 232.96it/s]\n",
      "TRAINING: mean epoch loss = 0.001672: : 6542it [01:08, 94.83it/s]\n",
      "VALIDATION: mean epoch loss = 0.001698: : 1636it [00:07, 232.04it/s]\n",
      "TRAINING: mean epoch loss = 0.001675: : 6542it [01:07, 96.48it/s]\n",
      "VALIDATION: mean epoch loss = 0.001691: : 1636it [00:07, 231.94it/s]\n",
      "TRAINING: mean epoch loss = 0.001671: : 6542it [01:08, 96.18it/s]\n",
      "VALIDATION: mean epoch loss = 0.001693: : 1636it [00:07, 232.80it/s]\n",
      "TRAINING: mean epoch loss = 0.001671: : 6542it [01:08, 95.27it/s]\n",
      "VALIDATION: mean epoch loss = 0.00168: : 1636it [00:07, 229.14it/s] \n",
      "TRAINING: mean epoch loss = 0.001674: : 6542it [01:08, 95.53it/s]\n",
      "VALIDATION: mean epoch loss = 0.001685: : 1636it [00:07, 220.97it/s]\n",
      "TRAINING: mean epoch loss = 0.001677: : 6542it [01:07, 97.28it/s]\n",
      "VALIDATION: mean epoch loss = 0.001713: : 1636it [00:07, 232.30it/s]\n",
      "TRAINING: mean epoch loss = 0.001673: : 6542it [01:07, 97.17it/s]\n",
      "VALIDATION: mean epoch loss = 0.001694: : 1636it [00:07, 232.53it/s]\n",
      "TRAINING: mean epoch loss = 0.001667: : 6542it [01:08, 96.00it/s]\n",
      "VALIDATION: mean epoch loss = 0.00169: : 1636it [00:07, 233.03it/s] \n",
      "TRAINING: mean epoch loss = 0.001672: : 6542it [01:09, 93.97it/s]\n",
      "VALIDATION: mean epoch loss = 0.001699: : 1636it [00:07, 232.14it/s]\n",
      "TRAINING: mean epoch loss = 0.001663: : 6542it [01:07, 96.25it/s]\n",
      "VALIDATION: mean epoch loss = 0.001691: : 1636it [00:07, 229.85it/s]\n",
      "TRAINING: mean epoch loss = 0.001668: : 6542it [01:09, 93.61it/s]\n",
      "VALIDATION: mean epoch loss = 0.001683: : 1636it [00:07, 218.20it/s]\n",
      "TRAINING: mean epoch loss = 0.001665: : 6542it [01:09, 93.58it/s]\n",
      "VALIDATION: mean epoch loss = 0.001692: : 1636it [00:07, 232.37it/s]\n",
      "TRAINING: mean epoch loss = 0.001672: : 6542it [01:07, 96.77it/s]\n",
      "VALIDATION: mean epoch loss = 0.001681: : 1636it [00:07, 233.20it/s]\n",
      "TRAINING: mean epoch loss = 0.00167: : 6542it [01:08, 96.11it/s] \n",
      "VALIDATION: mean epoch loss = 0.001676: : 1636it [00:07, 232.23it/s]\n",
      "TRAINING: mean epoch loss = 0.001665: : 6542it [01:07, 97.14it/s]\n",
      "VALIDATION: mean epoch loss = 0.001687: : 1636it [00:07, 231.09it/s]\n",
      "TRAINING: mean epoch loss = 0.001666: : 6542it [01:07, 96.94it/s]\n",
      "VALIDATION: mean epoch loss = 0.001676: : 1636it [00:07, 233.16it/s]\n",
      "TRAINING: mean epoch loss = 0.00167: : 6542it [01:07, 97.25it/s] \n",
      "VALIDATION: mean epoch loss = 0.001671: : 1636it [00:07, 221.36it/s]\n",
      "TRAINING: mean epoch loss = 0.001677: : 6542it [01:07, 96.77it/s]\n",
      "VALIDATION: mean epoch loss = 0.001685: : 1636it [00:07, 232.40it/s]\n",
      "TRAINING: mean epoch loss = 0.001668: : 6542it [01:07, 96.82it/s]\n",
      "VALIDATION: mean epoch loss = 0.00168: : 1636it [00:07, 230.99it/s] \n",
      "TRAINING: mean epoch loss = 0.001662: : 6542it [01:07, 96.38it/s]\n",
      "VALIDATION: mean epoch loss = 0.001677: : 1636it [00:07, 232.30it/s]\n",
      "TRAINING: mean epoch loss = 0.001667: : 6542it [01:07, 96.81it/s]\n",
      "VALIDATION: mean epoch loss = 0.001687: : 1636it [00:07, 232.00it/s]\n",
      "TRAINING: mean epoch loss = 0.001679: : 6542it [01:07, 96.88it/s]\n",
      "VALIDATION: mean epoch loss = 0.001679: : 1636it [00:07, 231.64it/s]\n",
      "TRAINING: mean epoch loss = 0.001675: : 6542it [01:07, 96.42it/s]\n",
      "VALIDATION: mean epoch loss = 0.001675: : 1636it [00:07, 219.64it/s]\n",
      "TRAINING: mean epoch loss = 0.001671: : 6542it [01:07, 96.98it/s]\n",
      "VALIDATION: mean epoch loss = 0.001673: : 1636it [00:07, 232.33it/s]\n",
      "TRAINING: mean epoch loss = 0.001674: : 6542it [01:07, 97.01it/s]\n",
      "VALIDATION: mean epoch loss = 0.001705: : 1636it [00:07, 231.64it/s]\n",
      "TRAINING: mean epoch loss = 0.001665: : 6542it [01:09, 94.45it/s]\n",
      "VALIDATION: mean epoch loss = 0.001669: : 1636it [00:07, 221.54it/s]\n",
      "TRAINING: mean epoch loss = 0.001653: : 6542it [01:09, 94.21it/s]\n",
      "VALIDATION: mean epoch loss = 0.001673: : 1636it [00:07, 225.39it/s]\n",
      "TRAINING: mean epoch loss = 0.001653: : 6542it [01:09, 93.63it/s]\n",
      "VALIDATION: mean epoch loss = 0.001659: : 1636it [00:07, 225.01it/s]\n",
      "TRAINING: mean epoch loss = 0.001655: : 6542it [01:09, 93.76it/s]\n",
      "VALIDATION: mean epoch loss = 0.001667: : 1636it [00:07, 214.65it/s]\n",
      "TRAINING: mean epoch loss = 0.001658: : 6542it [01:09, 94.76it/s]\n",
      "VALIDATION: mean epoch loss = 0.001677: : 1636it [00:07, 226.42it/s]\n",
      "TRAINING: mean epoch loss = 0.001656: : 6542it [01:09, 94.05it/s]\n",
      "VALIDATION: mean epoch loss = 0.001668: : 1636it [00:07, 223.32it/s]\n",
      "TRAINING: mean epoch loss = 0.00165: : 6542it [01:10, 92.86it/s] \n",
      "VALIDATION: mean epoch loss = 0.001651: : 1636it [00:07, 224.86it/s]\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(h5n.parameters(), lr=0.000001)\n",
    "label_dict = {1: 0, 6: 1, 7: 2, 8: 3, 9: 4}\n",
    "\n",
    "n_epochs = 100\n",
    "\n",
    "for e in range(n_epochs):\n",
    "    training_loss = 0\n",
    "    t_bar = tqdm(enumerate(train_loader), desc='TRAINING')\n",
    "    for b,  batch in t_bar:\n",
    "        batch.z = torch.Tensor([label_dict[int(x)] for x in batch.z]).type(torch.int64)\n",
    "        batch.to('cuda')\n",
    "        pred = h5n(batch)\n",
    "        target = batch.y[:, 13][:, None] / 120  # very crude normalization! (should substract upper & lower limit etc)\n",
    "        loss = criterion(-1 * pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        training_loss = (training_loss * b + loss) / (b + 1)\n",
    "        if b % 100 == 0:\n",
    "            t_bar.set_description('TRAINING: mean epoch loss = '+str(round(float(training_loss), 6)))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        validation_loss = 0\n",
    "        t_bar = tqdm(enumerate(validation_loader), desc='VALIDATION')\n",
    "        for b,  batch in t_bar:\n",
    "            batch.z = torch.Tensor([label_dict[int(x)] for x in batch.z]).type(torch.int64)\n",
    "            batch.to('cuda')\n",
    "            pred = h5n(batch)\n",
    "            target = batch.y[:, 13][:, None] / 120\n",
    "            loss = criterion(-1 * pred, target)\n",
    "            validation_loss = (validation_loss * b + loss) / (b + 1)\n",
    "            if b % 100 == 0:\n",
    "                t_bar.set_description('VALIDATION: mean epoch loss = '+str(round(float(validation_loss), 6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "quarterly-error",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(h5n.state_dict(), model_path+'h5n.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-edwards",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-telling",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dried-french",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
